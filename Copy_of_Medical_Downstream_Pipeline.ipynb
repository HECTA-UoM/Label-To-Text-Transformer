{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yNoR1DKDSLsW"
      },
      "source": [
        "## Imports"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8KqigfXucsgS",
        "outputId": "7da4dbe0-afe9-4c95-9dd6-f4f716131964"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive', force_remount=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S-44RtPoiQ7H",
        "outputId": "c3679c4c-a5bc-47be-9c3a-b1d82eb02e07"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting en-core-web-lg==3.7.1\n",
            "  Downloading https://github.com/explosion/spacy-models/releases/download/en_core_web_lg-3.7.1/en_core_web_lg-3.7.1-py3-none-any.whl (587.7 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m587.7/587.7 MB\u001b[0m \u001b[31m2.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: spacy<3.8.0,>=3.7.2 in /usr/local/lib/python3.10/dist-packages (from en-core-web-lg==3.7.1) (3.7.4)\n",
            "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-lg==3.7.1) (3.0.12)\n",
            "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-lg==3.7.1) (1.0.5)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-lg==3.7.1) (1.0.10)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-lg==3.7.1) (2.0.8)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-lg==3.7.1) (3.0.9)\n",
            "Requirement already satisfied: thinc<8.3.0,>=8.2.2 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-lg==3.7.1) (8.2.3)\n",
            "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-lg==3.7.1) (1.1.2)\n",
            "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-lg==3.7.1) (2.4.8)\n",
            "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-lg==3.7.1) (2.0.10)\n",
            "Requirement already satisfied: weasel<0.4.0,>=0.1.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-lg==3.7.1) (0.3.4)\n",
            "Requirement already satisfied: typer<0.10.0,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-lg==3.7.1) (0.9.0)\n",
            "Requirement already satisfied: smart-open<7.0.0,>=5.2.1 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-lg==3.7.1) (6.4.0)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-lg==3.7.1) (4.66.2)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-lg==3.7.1) (2.31.0)\n",
            "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-lg==3.7.1) (2.6.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-lg==3.7.1) (3.1.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-lg==3.7.1) (67.7.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-lg==3.7.1) (23.2)\n",
            "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-lg==3.7.1) (3.3.0)\n",
            "Requirement already satisfied: numpy>=1.19.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-lg==3.7.1) (1.25.2)\n",
            "Requirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<3.8.0,>=3.7.2->en-core-web-lg==3.7.1) (0.6.0)\n",
            "Requirement already satisfied: pydantic-core==2.16.3 in /usr/local/lib/python3.10/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<3.8.0,>=3.7.2->en-core-web-lg==3.7.1) (2.16.3)\n",
            "Requirement already satisfied: typing-extensions>=4.6.1 in /usr/local/lib/python3.10/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<3.8.0,>=3.7.2->en-core-web-lg==3.7.1) (4.10.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.2->en-core-web-lg==3.7.1) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.2->en-core-web-lg==3.7.1) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.2->en-core-web-lg==3.7.1) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.2->en-core-web-lg==3.7.1) (2024.2.2)\n",
            "Requirement already satisfied: blis<0.8.0,>=0.7.8 in /usr/local/lib/python3.10/dist-packages (from thinc<8.3.0,>=8.2.2->spacy<3.8.0,>=3.7.2->en-core-web-lg==3.7.1) (0.7.11)\n",
            "Requirement already satisfied: confection<1.0.0,>=0.0.1 in /usr/local/lib/python3.10/dist-packages (from thinc<8.3.0,>=8.2.2->spacy<3.8.0,>=3.7.2->en-core-web-lg==3.7.1) (0.1.4)\n",
            "Requirement already satisfied: click<9.0.0,>=7.1.1 in /usr/local/lib/python3.10/dist-packages (from typer<0.10.0,>=0.3.0->spacy<3.8.0,>=3.7.2->en-core-web-lg==3.7.1) (8.1.7)\n",
            "Requirement already satisfied: cloudpathlib<0.17.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from weasel<0.4.0,>=0.1.0->spacy<3.8.0,>=3.7.2->en-core-web-lg==3.7.1) (0.16.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->spacy<3.8.0,>=3.7.2->en-core-web-lg==3.7.1) (2.1.5)\n",
            "Installing collected packages: en-core-web-lg\n",
            "Successfully installed en-core-web-lg-3.7.1\n",
            "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
            "You can now load the package via spacy.load('en_core_web_lg')\n",
            "\u001b[38;5;3m⚠ Restart to reload dependencies\u001b[0m\n",
            "If you are in a Jupyter or Colab notebook, you may need to restart Python in\n",
            "order to load all the package's dependencies. You can do this by selecting the\n",
            "'Restart kernel' or 'Restart runtime' option.\n"
          ]
        }
      ],
      "source": [
        "!python -m spacy download\n",
        "# maybe try en_core_sci_lg that is biomedical ? https://allenai.github.io/scispacy/"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eZFHPSEVl4oo",
        "outputId": "0285b052-10a3-4f88-a59d-de4608d6d803"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import pickle\n",
        "\n",
        "from torch.utils.data import DataLoader\n",
        "import random\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "from tqdm import tqdm\n",
        "\n",
        "from spacy.training import Example\n",
        "import random\n",
        "\n",
        "import spacy\n",
        "import os\n",
        "import datetime\n",
        "from google.colab import userdata, runtime\n",
        "import re\n",
        "\n",
        "import warnings\n",
        "\n",
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "import string\n",
        "\n",
        "import spacy\n",
        "from spacy.training import Example\n",
        "import random\n",
        "from tqdm import tqdm\n",
        "import copy\n",
        "\n",
        "nltk.download('stopwords')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VrLZ-YLncTTB"
      },
      "source": [
        "## Load Dataset & Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "IlQW5br3cyfj"
      },
      "outputs": [],
      "source": [
        "DATASET_DIR = '/content/drive/My Drive/_collaborations_/Synda_Health_Mile2/Dataset/' # data set, e.g. free text for deployment\n",
        "GENERATIONS_DIR = '/content/drive/My Drive/_collaborations_/Synda_Health_Mile2/EVALUATION/Medical_Generations/'\n",
        "SAVE_DIR = '/content/drive/My Drive/_collaborations_/Synda_Health_Mile2/EVALUATION/Downstream_Results/Medical/'\n",
        "\n",
        "training_set = pd.read_csv(DATASET_DIR + 'train.csv')\n",
        "# generations = pd.read_csv('path/to/generations')\n",
        "validation_set = pd.read_csv(DATASET_DIR + 'valid.csv')\n",
        "test_set = pd.read_csv(DATASET_DIR + 'test.csv')\n",
        "\n",
        "MASKING_RATIO = 0.5\n",
        "MODEL_NAME = 'roberta-large'\n",
        "\n",
        "REAL_EVALUATE = True\n",
        "GENERATIONS_EVALUATE = True\n",
        "\n",
        "stop_words = set(stopwords.words('english'))\n",
        "punctuation = set(string.punctuation)\n",
        "\n",
        "RUN_NAME = [\"roberta-large - Run - 02-11--14:40\", \"BiomedNLP-BiomedBERT-large-uncased-abstract - Run Medical - 03-02--18:56\"][1]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TCvpUmtsc4q6",
        "outputId": "2e0bc31d-45ef-4b40-b513-e922102a2248"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/spacy/util.py:910: UserWarning: [W095] Model 'en_core_sci_lg' (0.5.3) was trained with spaCy v3.6.1 and may not be 100% compatible with the current version (3.7.4). If you see errors or degraded performance, download a newer compatible model or retrain your custom model with the current spaCy version. For more details and available updates, run: python -m spacy validate\n",
            "  warnings.warn(warn_msg)\n",
            "/usr/local/lib/python3.10/dist-packages/spacy/util.py:1740: UserWarning: [W111] Jupyter notebook detected: if using `prefer_gpu()` or `require_gpu()`, include it in the same cell right before `spacy.load()` to ensure that the model is loaded on the correct device. More information: http://spacy.io/usage/v3#jupyter-notebook-gpu\n",
            "  warnings.warn(Warnings.W111)\n"
          ]
        }
      ],
      "source": [
        "nlp_sci = spacy.load(\"/content/drive/My Drive/_collaborations_/Synda_Health_Mile2/NER_Models/en_core_sci_lg\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "vNeILpKDb6z0"
      },
      "outputs": [],
      "source": [
        "data_train = training_set['Clinical Letters']\n",
        "data_valid = validation_set['Clinical Letters']\n",
        "data_test = test_set['Clinical Letters']"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_DasTI9-cVyk"
      },
      "source": [
        "## Get Entities & Train the Model"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data_train"
      ],
      "metadata": {
        "id": "i3UM_nhxuufo",
        "outputId": "4b68bd36-9cbe-4eff-8a2d-5feea0e4a10f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0      Please shower daily including washing incision...\n",
              "1      * Increasing pain * Fever * Inability to eat o...\n",
              "2      You were admitted to the hospital with a react...\n",
              "3      Dear Mr. Known lastname , You were admitted to...\n",
              "4      Please note: you have a mm nodule that was not...\n",
              "                             ...                        \n",
              "202    Please call the Hospital Clinic at Telephone/F...\n",
              "203    Dr. Known lastname , it was a pleasure to part...\n",
              "204    please call the Transplant Office Telephone/Fa...\n",
              "205                                          To Hospital\n",
              "206    # You were admitted to the hospital for shortn...\n",
              "Name: Clinical Letters, Length: 207, dtype: object"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "knc6Yl0gfN6j"
      },
      "outputs": [],
      "source": [
        "def get_entities(data):\n",
        "    all_entities = []\n",
        "\n",
        "    for doc in nlp_sci.pipe(data):\n",
        "        entities = [(ent.start_char, ent.end_char, ent.label_) for ent in doc.ents]\n",
        "        all_entities.append((doc.text, {'entities': entities}))\n",
        "\n",
        "    return all_entities\n",
        "\n",
        "\n",
        "# if len(generations.keys()) < 10:\n",
        "#     warnings.warn(f\"generations keys length: {len(generations.keys())}\")\n",
        "\n",
        "entities = dict()\n",
        "\n",
        "# entities['real'] = get_entities(data_train)\n",
        "generations_dict = dict()\n",
        "\n",
        "# with open(GENERATIONS_DIR + RUN_NAME + \".pkl\", \"rb\") as f:\n",
        "#     model_generations = pickle.load(f)\n",
        "\n",
        "# for option in model_generations.keys():\n",
        "#     if option == 'random':\n",
        "#         for key in model_generations[option].keys():\n",
        "#             generations = model_generations[option][key]\n",
        "#             generations_dict[key] = generations\n",
        "#     else:\n",
        "#         generations = model_generations[option]\n",
        "#         generations_dict[option] = generations\n",
        "\n",
        "# for key in generations_dict.keys():\n",
        "#     entities[key] = get_entities(list(generations_dict[key].values()))\n",
        "\n",
        "entities['train'] = get_entities(data_train)\n",
        "# entities['valid'] = get_entities(data_valid)\n",
        "# entities['test'] = get_entities(data_test)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "entities.keys()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4YnUIMw-wFeV",
        "outputId": "ad7fd3db-5a82-4c77-ef05-2315c873357c"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "dict_keys(['train'])"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "id": "X1-r4p3ytCdi",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5c626ab0-7588-4d82-bc9f-40eef921d16a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  0%|          | 0/1 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/spacy/util.py:1740: UserWarning: [W111] Jupyter notebook detected: if using `prefer_gpu()` or `require_gpu()`, include it in the same cell right before `spacy.load()` to ensure that the model is loaded on the correct device. More information: http://spacy.io/usage/v3#jupyter-notebook-gpu\n",
            "  warnings.warn(Warnings.W111)\n",
            "100%|██████████| 1/1 [01:45<00:00, 105.02s/it]\n"
          ]
        }
      ],
      "source": [
        "def evaluate_model(model, validation_data):\n",
        "    losses = {}\n",
        "    for text, annotations in validation_data:\n",
        "        doc = model.make_doc(text)\n",
        "        example = Example.from_dict(doc, annotations)\n",
        "        model.update([example], drop=0.0, losses=losses, sgd=None)\n",
        "\n",
        "    return losses['ner']\n",
        "\n",
        "EPOCHS = 3\n",
        "\n",
        "def train_model(training_data, validation_data):\n",
        "    model = spacy.load(\"en_core_web_lg\")\n",
        "\n",
        "    if \"ner\" not in model.pipe_names:\n",
        "        ner = model.create_pipe(\"ner\")\n",
        "        model.add_pipe(ner, last=True)\n",
        "    else:\n",
        "        ner = model.get_pipe(\"ner\")\n",
        "\n",
        "    ner.add_label('ENTITY')\n",
        "    other_pipes = [pipe for pipe in model.pipe_names if pipe != \"ner\"]\n",
        "\n",
        "    with model.disable_pipes(*other_pipes):\n",
        "        optimizer = model.resume_training()\n",
        "        best_loss = float('inf')\n",
        "        best_model = None\n",
        "\n",
        "        for epoch in range(EPOCHS): # setup epoch num\n",
        "            random.shuffle(training_data)\n",
        "            losses = {}\n",
        "\n",
        "            for text, annotations in training_data:\n",
        "                doc = model.make_doc(text) #model to be trained\n",
        "                example = Example.from_dict(doc, annotations) # pack predication and expected/gold labels\n",
        "                model.update([example], drop=0.5, losses=losses, sgd=optimizer) # the loss to be minimised\n",
        "\n",
        "            val_loss = evaluate_model(model, validation_data) # validation - not really need in some situration\n",
        "\n",
        "            if val_loss < best_loss:\n",
        "                best_loss = val_loss\n",
        "                best_model = copy.deepcopy(model)\n",
        "\n",
        "    return best_model # return the best model that can be deployed.\n",
        "\n",
        "\n",
        "models = dict()\n",
        "\n",
        "for key in tqdm(list(entities.keys())):\n",
        "    if key in ['valid', 'test']:\n",
        "        continue\n",
        "\n",
        "    models[key] = train_model(training_data=entities[key], validation_data=entities['train'])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ddJJfW0miy8U"
      },
      "source": [
        "## Evaluate The Model"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "You were admitted with severe pancreatitis from gallstones. You were treated supportively during this and you improved. You required intubation twice to support your breathing. You were treated for pneumonia, acute kidney failure and aspiration. You are now improving and being sent to an acute rehabilitation facility. In the future it will be important for you to have a cholecystectomy in - months, once you have completely recovered from this hospitalization. You will also need to have follow up imaging of your lungs in months given the pulmonary nodules found during this admission. Some of your medications have changed: We have stopped actos and metformin. These were changed to insulin while you were sick. Once you go home you can restart these. We have stopped amlodipine. We have halved your lisinopril. We have started trazodone, simethicone, senna, colace, bisacodyl, insulin and lidocaine patch."
      ],
      "metadata": {
        "id": "8N24RPDi0pxD"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fpu5kWIRhRKu",
        "outputId": "a54fae58-685b-4f0a-dd1c-7c1406f91c9a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1/1 [00:02<00:00,  2.17s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Precision: 0.030669285390542377\n",
            "Recall: 0.03789434384916931\n",
            "F1 Score: 0.033901135604542415\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'train': 0.033901135604542415}"
            ]
          },
          "metadata": {},
          "execution_count": 32
        }
      ],
      "source": [
        "def evaluate_model(model):\n",
        "    correct = 0\n",
        "    predicted_total = 0\n",
        "    actual_total = 0\n",
        "\n",
        "    for text, original_annotation in zip(training_set['Clinical Letters'], entities['train']):\n",
        "        doc = model(text) # in real setting, this returns the labels of input text by deploying saved best model.\n",
        "        predicted_entities = set((ent.text, ent.label_) for ent in doc.ents) # extracting entities attached to text\n",
        "        original_entities_set = set((text[start:end], label) for start, end, label in original_annotation[1]['entities']) # this gold label for evaluation purpose, not needed for deployment\n",
        "        correct += len(predicted_entities.intersection(original_entities_set))\n",
        "        predicted_total += len(predicted_entities)\n",
        "        actual_total += len(original_entities_set)\n",
        "\n",
        "    precision = correct / predicted_total if predicted_total > 0 else 0\n",
        "    recall = correct / actual_total if actual_total > 0 else 0\n",
        "    f1 = 2 * (precision * recall) / (precision + recall) if (precision + recall) > 0 else 0\n",
        "\n",
        "    print(f\"Precision: {precision}\")\n",
        "    print(f\"Recall: {recall}\")\n",
        "    print(f\"F1 Score: {f1}\")\n",
        "\n",
        "    return f1\n",
        "\n",
        "\n",
        "results = dict()\n",
        "\n",
        "for key in tqdm(models.keys()):\n",
        "    results[key] = evaluate_model(models[key])\n",
        "\n",
        "results"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "doc = models['train'](\"You were admitted with severe pancreatitis from gallstones. You were treated supportively during this and you improved. You required intubation twice to support your breathing. You were treated for pneumonia, acute kidney failure and aspiration. You are now improving and being sent to an acute rehabilitation facility. In the future it will be important for you to have a cholecystectomy in - months, once you have completely recovered from this hospitalization. You will also need to have follow up imaging of your lungs in months given the pulmonary nodules found during this admission. Some of your medications have changed: We have stopped actos and metformin. These were changed to insulin while you were sick. Once you go home you can restart these. We have stopped amlodipine. We have halved your lisinopril. We have started trazodone, simethicone, senna, colace, bisacodyl, insulin and lidocaine patch.\")"
      ],
      "metadata": {
        "id": "jWLxldTFy_Xo"
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "list((ent.text, ent.label_) for ent in doc.ents)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xB2l_wGl02Fq",
        "outputId": "9ce95262-a2dd-4d85-de70-fc8b6df6b65f"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('admitted with', 'ENTITY'),\n",
              " ('severe', 'ENTITY'),\n",
              " ('pancreatitis', 'ENTITY'),\n",
              " ('gallstones', 'ENTITY'),\n",
              " ('treated supportively', 'ENTITY'),\n",
              " ('improved', 'ENTITY'),\n",
              " ('intubation', 'ENTITY'),\n",
              " ('breathing', 'ENTITY'),\n",
              " ('treated', 'ENTITY'),\n",
              " ('pneumonia', 'ENTITY'),\n",
              " ('acute kidney failure', 'ENTITY'),\n",
              " ('aspiration', 'ENTITY'),\n",
              " ('improving', 'ENTITY'),\n",
              " ('acute rehabilitation facility', 'ENTITY'),\n",
              " ('cholecystectomy', 'ENTITY'),\n",
              " ('months', 'ENTITY'),\n",
              " ('recovered', 'ENTITY'),\n",
              " ('hospitalization', 'ENTITY'),\n",
              " ('follow up', 'ENTITY'),\n",
              " ('imaging', 'ENTITY'),\n",
              " ('lungs', 'ENTITY'),\n",
              " ('months', 'ENTITY'),\n",
              " ('pulmonary nodules', 'ENTITY'),\n",
              " ('admission', 'ENTITY'),\n",
              " ('medications', 'ENTITY'),\n",
              " ('actos', 'ENTITY'),\n",
              " ('metformin', 'ENTITY'),\n",
              " ('insulin', 'ENTITY'),\n",
              " ('sick', 'ENTITY'),\n",
              " ('restart', 'ENTITY'),\n",
              " ('amlodipine', 'ENTITY'),\n",
              " ('halved', 'ENTITY'),\n",
              " ('lisinopril', 'ENTITY'),\n",
              " ('trazodone', 'ENTITY'),\n",
              " ('simethicone', 'ENTITY'),\n",
              " ('senna', 'ENTITY'),\n",
              " ('colace', 'ENTITY'),\n",
              " ('bisacodyl', 'ENTITY'),\n",
              " ('insulin', 'ENTITY'),\n",
              " ('lidocaine patch', 'ENTITY')]"
            ]
          },
          "metadata": {},
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "list((ent.text) for ent in doc.ents)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3addllcz1MHp",
        "outputId": "cadf1c94-b38f-46f1-a479-73cd6c8f48e3"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['admitted with',\n",
              " 'severe',\n",
              " 'pancreatitis',\n",
              " 'gallstones',\n",
              " 'treated supportively',\n",
              " 'improved',\n",
              " 'intubation',\n",
              " 'breathing',\n",
              " 'treated',\n",
              " 'pneumonia',\n",
              " 'acute kidney failure',\n",
              " 'aspiration',\n",
              " 'improving',\n",
              " 'acute rehabilitation facility',\n",
              " 'cholecystectomy',\n",
              " 'months',\n",
              " 'recovered',\n",
              " 'hospitalization',\n",
              " 'follow up',\n",
              " 'imaging',\n",
              " 'lungs',\n",
              " 'months',\n",
              " 'pulmonary nodules',\n",
              " 'admission',\n",
              " 'medications',\n",
              " 'actos',\n",
              " 'metformin',\n",
              " 'insulin',\n",
              " 'sick',\n",
              " 'restart',\n",
              " 'amlodipine',\n",
              " 'halved',\n",
              " 'lisinopril',\n",
              " 'trazodone',\n",
              " 'simethicone',\n",
              " 'senna',\n",
              " 'colace',\n",
              " 'bisacodyl',\n",
              " 'insulin',\n",
              " 'lidocaine patch']"
            ]
          },
          "metadata": {},
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NKkhqmxEcjzx"
      },
      "source": [
        "## Save Results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "TVbB8pHHB6Op"
      },
      "outputs": [],
      "source": [
        "with open(SAVE_DIR + f'{RUN_NAME}_movie_evaluation_results.pkl', 'wb') as f:\n",
        "    pickle.dump(results, f)\n",
        "\n",
        "with open(SAVE_DIR + f'{RUN_NAME}_movie_evaluation_results.txt', 'w') as f:\n",
        "    f.write(str(results))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "70SQyMZHMK3C"
      },
      "outputs": [],
      "source": [
        "from google.colab import runtime\n",
        "runtime.unassign()"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "machine_shape": "hm",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}